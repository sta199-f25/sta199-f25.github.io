{
  "hash": "b5ea47899be1db92a4767bfef6e28e53",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Making decisions\"\nsubtitle: \"Lecture 25\"\ndate: \"2025-12-02\"\nformat: \n  revealjs: \n    output-file: 25-making-decisions-slides.html\n    footer: \"[ðŸ”— sta199-f25.github.io](https://sta199-f25.github.io/)\"\n    theme: slides.scss\n    transition: fade\n    slide-number: true\n    logo: images/logo.png\n    pdf-separate-fragments: true\n    toc: false\n  html: \n    code-link: true\nfilters: \n  - ../remove-fmt-skip.lua\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n# Warm-up\n\n## It's Giving Tuesday -- Give feedback!\n\n::: {.columns}\n\n::: {.column width=\"30%\".xsmall}\n\n-  Take 2 minutes to fill out the TA evaluation form -- link in your email! Due Monday, December 8th.\n\n-  Nominate a TA for the StatSci TA of the Year award by sending an email to <dus@stat.duke.edu> with a brief narrative for your nomination.\n\n:::\n\n::: {.column width=\"70%\"}\n\n![](images/25/ta-1.png){width=\"200px\"} ![](images/25/ta-2.png){width=\"200px\"} ![](images/25/ta-3.png){width=\"200px\"}\n\n:::\n\n::: \n\n::: xsmall\n-  Please also fill out the course evaluation (on DukeHub) as well, I'd love to your feedback!\n:::\n\n## Announcements {.xsmall}\n\n- HW:\n  - HW 5 accepted until Wed, Dec 3 at 11:59 pm without penalty\n  - HW 6 due at 11:59 pm on Fri, Dec 6, accepted until Sun, Dec 7 at 11:59 pm without penalty\n\n- Final exam: \n  - Classroom: Half of you will take it in this room (Bio Sci 111) the other half in (Physics 128), check your email for your classroom assignment\n  - Review: During reading period, date/time TBA\n  - Office hours: TBA soon as review session is scheduled\n\n# From last time\n\n## Participate ðŸ“±ðŸ’» {.xsmall}\n\n::: columns\n\n::: {.column width=\"70%\"}\n\n::: wooclap\n\nWhich of the following is true about confidence intervals?\n\n::: wooclap-choices\n- They're for a sample statistic.\n- They're for a population parameter.\n- They can be either for both a sample statistic or a population parameter.\n- They're neither for a sample statistic nor a population parameter.\n:::\n\n:::\n\n:::\n\n::: {.column width=\"30%\"}\n![](images/wooclap-qr.png){width=\"200\" fig-align=\"center\"}\n\n::: small\nScan the QR code or go to [app.wooclap.com/sta199](https://app.wooclap.com/sta199). Log in with your Duke NetID.\n:::\n\n:::\n\n:::\n\n## Why do we construct confidence intervals?\n\nTo estimate plausible values of a parameter of interest, e.g., \n\n- a slope ($\\beta_1$)\n- a mean ($\\mu$)\n- a proportion ($p$)\n- etc.\n\n## What is bootstrapping?\n\n-   Bootstrapping is a statistical procedure that resamples(with replacement) a single data set to create many simulated samples.\n\n-   We then use these simulated samples to quantify the uncertainty around the sample statistic we're interested in, e.g., a slope ($b_1$), a mean ($\\bar{x}$), a proportion ($\\hat{p}$).\n\n## Setup\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(openintro)\n```\n:::\n\n\n## Computing the CI for the slope I\n\nCalculate the observed slope:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobserved_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\nobserved_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept  116652.\n2 area          159.\n```\n\n\n:::\n:::\n\n\n## Computing the CI for the slope II {.smaller}\n\nTake `1000` bootstrap samples and fit models to each one:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"1,5,6\"}\nset.seed(1120)\n\nboot_fits <- duke_forest |>\n  specify(price ~ area) |>\n  generate(reps = 1000, type = \"bootstrap\") |>\n  fit()\n\nboot_fits\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term      estimate\n       <int> <chr>        <dbl>\n 1         1 intercept   47819.\n 2         1 area          191.\n 3         2 intercept  144645.\n 4         2 area          134.\n 5         3 intercept  114008.\n 6         3 area          161.\n 7         4 intercept  100639.\n 8         4 area          166.\n 9         5 intercept  215264.\n10         5 area          125.\n# â„¹ 1,990 more rows\n```\n\n\n:::\n:::\n\n\n## What does each observation on the plot represent? {.smaller}\n\n::: {.columns}\n\n::: {.column}\n-   Resample, with replacement, from the original data\n-   Do this `reps = 1000` times\n-   Calculate the summary statistic of interest in each of these samples\n:::\n\n::: {.column}\n\n::: {.cell}\n::: {.cell-output-display}\n![](25-making-decisions_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n:::\n\n:::\n\n## Computing the CI for the slope III\n\n**Percentile method:** Compute the 95% CI as the middle 95% of the bootstrap distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"5\"}\nget_confidence_interval(\n  boot_fits,\n  point_estimate = observed_fit,\n  level = 0.95,\n  type = \"percentile\" # default method\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          87.5     216.\n2 intercept -24293.   300646.\n```\n\n\n:::\n:::\n\n\n## Participate ðŸ“±ðŸ’» {.xsmall}\n\n::: columns\n\n::: {.column width=\"70%\"}\n\n::: wooclap\n\nIf you want to be very certain (i.e., more confident) that you capture the population parameter, should we use a wider or a narrower interval?\n\n::: wooclap-choices\n- Wider \n- Narrower\n- Depends on the situation\n:::\n\n:::\n\n:::\n\n::: {.column width=\"30%\"}\n![](images/wooclap-qr.png){width=\"200\" fig-align=\"center\"}\n\n::: small\nScan the QR code or go to [app.wooclap.com/sta199](https://app.wooclap.com/sta199). Log in with your Duke NetID.\n:::\n\n:::\n\n:::\n\n## Precision vs. accuracy {.smaller}\n\n::: task\nWhat drawbacks are associated with using a wider interval?\n:::\n\n. . .\n\n![](images/25/garfield.png)\n\n## Precision vs. accuracy {.smaller}\n\n::: task\nHow can we get best of both worlds -- high precision and high accuracy?\n:::\n\n## Recap {.xsmall}\n\n::: incremental\n\n-   **Population:** Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. -- population size = $N$\n\n-   **Sample:** Subset of the population, ideally random and representative -- sample size = $n$\n\n-   Sample statistic $\\ne$ population parameter, but if the sample is good, it can be a good estimate\n\n-   **Statistical inference:** Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process\n\n-   We report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population\n\n-   Since we can't continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability\n\n:::\n\n## An alternative approach\n\n**Standard error method:** Compute the 95% CI as the observed slope plus/minus ~2 * standard error (the standard deviation of the bootstrap distribution):\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code  code-line-numbers=\"5\"}\nget_confidence_interval(\n  boot_fits,\n  point_estimate = observed_fit,\n  level = 0.95,\n  type = \"se\"\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 3\n  term      lower_ci upper_ci\n  <chr>        <dbl>    <dbl>\n1 area          95.5     223.\n2 intercept -42990.   276295.\n```\n\n\n:::\n:::\n\n\n## Margin of error\n\nThat quantity (~2 * standard error) is called the **margin of error**, e.g.,\n\n![](images/25/cnn-poll.png){width=\"700px}\n\n::: aside\nSource: <https://www.cnn.com/polling/approval/trump-polls>\n:::\n\n## On the horizon... {.smaller}\n\n::: incremental\n-   In this class you learned how to construct a confidence interval (i.e., calculate the margin of error) using a computational method called bootstrapping.\n\n-   The bootstrap distributions you constructed (given enough `reps` -- repeated samples) were unimodal and symmetric around the observed statistic.\n\n-   This is not a happenstance! And there is theory behind it... It's called the **Central Limit Theorem**!\n\n-   You can learn about the Central Limit Theorem and theory-based methods for constructing confidence intervals (and other inference procedures) in future stats courses.\n:::\n\n## Syntax notes {.smaller}\n\n-   Bootstrapping for categorical data\n\n    -   `specify(response = x, success = \"success level\")`\n\n    -   `calculate(stat = \"prop\")`\n\n. . .\n\n- Bootstrapping for other `stat`s\n\n    -   `calculate()` documentation: [infer.tidymodels.org/reference/calculate.html](https://infer.tidymodels.org/reference/calculate.html)\n\n    -   **infer** pipelines: [infer.tidymodels.org/articles/observed_stat_examples.html](https://infer.tidymodels.org/articles/observed_stat_examples.html)\n\n# Hypothesis testing\n\n## Hypothesis testing {.smaller}\n\nA hypothesis test is a statistical technique used to evaluate *competing claims* using data\n\n::: incremental\n-   **Null hypothesis,** $H_0$: An assumption about the population.\n    \"There is nothing going on.\"\n\n-   **Alternative hypothesis,** $H_A$: A research question about the population.\n    \"There is something going on\".\n:::\n\n. . .\n\n::: callout-note\nHypotheses are always at the population level!\n:::\n\n## Setting hypotheses\n\n-   **Null hypothesis,** $H_0$: \"There is nothing going on.\" The slope of the model for predicting the prices of houses in Duke Forest from their areas is 0, $\\beta_1 = 0$.\n\n-   **Alternative hypothesis,** $H_A$: \"There is something going on\".\n    The slope of the model for predicting the prices of houses in Duke Forest from their areas is different than, $\\beta_1 \\ne 0$.\n\n## Hypothesis testing \"mindset\"\n\n-   Assume you live in a world where null hypothesis is true: $\\beta_1 = 0$.\n\n-   Ask yourself how likely you are to observe the sample statistic, or something even more extreme, in this world: \n\n$$P \\big( b_1 \\leq -159~or~b_1 \\geq 159 ~|~ \\beta_1 = 0 \\big)$$\n\n## Hypothesis testing as a court trial {.smaller}\n\n-   **Null hypothesis**, $H_0$: Defendant is innocent\n\n-   **Alternative hypothesis**, $H_A$: Defendant is guilty\n\n. . .\n\n-   **Present the evidence:** Collect data\n\n. . .\n\n-   **Judge the evidence:** \"Could these data plausibly have happened by chance if the null hypothesis were true?\"\n    -   Yes: Fail to reject $H_0$\n    -   No: Reject $H_0$\n\n## Hypothesis testing framework {.smaller}\n\n::: incremental\n-   Start with a null hypothesis, $H_0$, that represents the status quo\n\n-   Set an alternative hypothesis, $H_A$, that represents the research question, i.e. what weâ€™re testing for\n\n-   Conduct a hypothesis test under the assumption that the null hypothesis is true and calculate a **p-value** (probability of observed or more extreme outcome given that the null hypothesis is true)\n\n    -   if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\n    -   if they do, then reject the null hypothesis in favor of the alternative\n:::\n\n## Calculate observed slope\n\n...\nwhich we have already done:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nobserved_fit <- duke_forest |>\n  specify(price ~ area) |>\n  fit()\n\nobserved_fit\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term      estimate\n  <chr>        <dbl>\n1 intercept  116652.\n2 area          159.\n```\n\n\n:::\n:::\n\n\n## Simulate null distribution\n\n\n::: {.cell}\n\n```{.r .cell-code  code-line-numbers=\"|1|2|3|4|5|6\"}\nset.seed(20251202)\nnull_dist <- duke_forest |>\n  specify(price ~ area) |>\n  hypothesize(null = \"independence\") |>\n  generate(reps = 1000, type = \"permute\") |>\n  fit()\n```\n:::\n\n\n## View null distribution {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,000 Ã— 3\n# Groups:   replicate [1,000]\n   replicate term       estimate\n       <int> <chr>         <dbl>\n 1         1 intercept 594889.  \n 2         1 area         -12.6 \n 3         2 intercept 477930.  \n 4         2 area          29.5 \n 5         3 intercept 581950.  \n 6         3 area          -7.93\n 7         4 intercept 487542.  \n 8         4 area          26.0 \n 9         5 intercept 643406.  \n10         5 area         -30.0 \n# â„¹ 1,990 more rows\n```\n\n\n:::\n:::\n\n\n## Visualize null distribution {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvisualize(null_dist)\n```\n\n::: {.cell-output-display}\n![](25-making-decisions_files/figure-revealjs/unnamed-chunk-10-1.png){width=960}\n:::\n:::\n\n\n## Visualize null distribution + p-value\n\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nvisualize(null_dist) +\n  shade_p_value(\n    obs_stat = observed_fit, \n    direction = \"two-sided\"\n  )\n```\n\n::: {.cell-output-display}\n![](25-making-decisions_files/figure-revealjs/unnamed-chunk-11-1.png){width=960}\n:::\n:::\n\n\n## Get p-value {.smaller}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnull_dist |>\n  get_p_value(obs_stat = observed_fit, direction = \"two-sided\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Please be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the\n`generate()` step.\nâ„¹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\nPlease be cautious in reporting a p-value of 0. This result is an\napproximation based on the number of `reps` chosen in the\n`generate()` step.\nâ„¹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 2\n  term      p_value\n  <chr>       <dbl>\n1 area            0\n2 intercept       0\n```\n\n\n:::\n:::\n\n\n## Make a decision\n\n::: task\nBased on the p-value calculated, what is the conclusion of the hypothesis test?\n:::\n",
    "supporting": [
      "25-making-decisions_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}