---
title: "Evaluating models"
subtitle: "Lecture 22"
date: "2025-11-13"
format: 
  revealjs: 
    output-file: 21-evaluating-models-slides.html
    footer: "[ðŸ”— sta199-f25.github.io](https://sta199-f25.github.io/)"
    theme: slides.scss
    transition: fade
    slide-number: true
    logo: images/logo.png
    pdf-separate-fragments: true
    toc: false
  html: 
    code-link: true
filters: 
  - ../remove-fmt-skip.lua
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
ggplot2::theme_set(ggplot2::theme_bw(base_size = 24))
todays_ae <- "ae-14-chicago-taxi-classification"
```

# Warm-up

## While you wait: Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

What is sensitivity also known as?

::: wooclap-choices
- True positive rate
- True negative rate
- False positive rate
- False negative rate
- Recall
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Announcements

- Projects due tonight, peer evals due tomorrow night

- Practice Exam 2 is posted on the course website

- Reply to post on Ed about requests for topics / concepts for exam review [[thread]](https://edstem.org/us/courses/80616/discussion/7304129)

## From last class: Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

Which of the following best describes the area annotated on the ROC curve?

![](images/22/roc-curve-annotated-question.png){width=500}

::: wooclap-choices
- Where all positives classified as positive, all negatives classified as negative
- Where true positive rate = false positive rate
- Where all positives classified as negative, all negatives classified as positive
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## ROC curve {.smaller}

::: task
Which corner of the plot indicates the best model performance?
:::

![](images/22/roc-curve-annotated.png)

# Next steps

## `{r} todays_ae` {.smaller}

::: appex
-   Go to your ae project in RStudio.

-   If you haven't yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there's nothing left in your Git pane.

-   If you haven't yet done so, click Pull to get today's application exercise file: *`{r} paste0(todays_ae, ".qmd")`*.

-   Work through the application exercise in class, and render, commit, and push your edits.
:::

## Recap {.smaller}

::: incremental
- Split data into training and testing sets (generally 75/25)

- Fit models on training data and reduce to a few candidate models

- Make predictions on testing data

- Evaluate predictions on testing data using appropriate predictive performance metrics
  - Linear models: Adjusted R-squared, AIC, etc.
  - Logistic models: False negative and positive rates, AUC (area under the curve), etc.

- Don't forget to also consider explainability and domain knowledge when selecting a final model

- In a future machine learning course: Cross-validation (partitioning training data into training and validation sets and repeating this many times to evaluate model predictive performance before using the testing data), feature engineering,  hyperparameter tuning, more complex models (random forests, gradient boosting machines, neural networks, etc.)
:::

. . .

::: callout-note
We will only learn about a subset of these in this course, but you can go further into these ideas in STA 210 or STA 221 as well as in various machine learning courses.
:::
