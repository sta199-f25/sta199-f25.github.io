---
title: "Web scraping<br>many pages"
subtitle: "Lecture 14"
date: "2025-10-09"
format: 
  revealjs: 
    output-file: 13-web-scraping-many-pages-slides.html
    footer: "[ðŸ”— sta199-f25.github.io](https://sta199-f25.github.io/)"
    theme: slides.scss
    transition: fade
    slide-number: true
    logo: images/logo.png
    pdf-separate-fragments: true
    toc: false
  html: 
    code-link: true
filters: 
  - ../remove-fmt-skip.lua
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
ggplot2::theme_set(ggplot2::theme_gray(base_size = 24))
todays_ae <- "ae-09-chronicle-scrape"
```

# Warm-up

## While you wait: Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

The following code in `chronicle-scrape.R` extracts titles of an opinion article from The Chronicle website:

```{r}
#| eval: false
page <- read_html(
  "https://www2.stat.duke.edu/~cr173/data/dukechronicle-opinion/www.dukechronicle.com/section/opinionabc4.html"
)

titles <- page |>
  html_elements(".space-y-4 .font-extrabold") |>
  html_text()
```

Which of the following needs to change to extract column titles instead?

::: wooclap-choices
- Change the URL in `read_html()`
- Change the function `html_elements()` to `html_element()`
- Change the CSS selector `.space-y-4 .font-extrabold` to `.space-y-4 .text-brand`
- Change the function `html_text()` to `html_attr()`
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Announcements {.smaller}

- HW 2, Question 7: Reproduce the colorful box plot -- We caught an error in grading (any theme with a white background would have worked). If you originally missed points due to not using `theme_bw()`, but you used another theme with a white background, we've updated your grade.

- Midsemester course survey due tonight at 11:59pm

- Project proposals (Milestone 2) + first peer evaluation due next Thursday at 11:59pm -- any questions?

# From last time

## Opinion articles in The Chronicle {.smaller}

Go to <https://www2.stat.duke.edu/~cr173/data/dukechronicle-opinion/www.dukechronicle.com/section/opinionabc4.html> (copy of The Chronicle opinion section as of October 7, 2025).

## Goal

::::: columns
::: {.column width="50%"}
-   Scrape data and organize it in a tidy format in R
-   Perform light text parsing to clean data
-   Summarize and visualze the data
:::

::: {.column width="50%"}
![](images/13/chronicle-data.png){fig-align="center"}
:::
:::::

## `{r} todays_ae` {.smaller}

::: appex
-   Go to your ae project in RStudio.

-   If you haven't yet done so, make sure all of your changes up to this point are committed and pushed, i.e., there's nothing left in your Git pane.

-   If you haven't yet done so, click Pull to get today's application exercise file: *`{r} paste0(todays_ae, ".qmd")`* and *`chronicle-scrape.R`*.
:::

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

Put the folllowing tasks in order to scrape data from a website:

::: wooclap-choices
- Use the SelectorGadget identify tags for elements you want to grab
- Use `read_html()` to read the page's source code into R
- Use other functions from the **rvest** package to parse the elements you're interested in
- Put the components together in a data frame (a tibble) and analyze it like you analyze any other data
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## A new R workflow {.smaller}

-   When working in a Quarto document, your analysis is re-run each time you knit

-   If web scraping in a Quarto document, you'd be re-scraping the data each time you knit, which is undesirable (and not *nice*)!

-   An alternative workflow:

    -   Use an R script to save your code
    -   Saving interim data scraped using the code in the script as CSV or RDS files
    -   Use the saved data in your analysis in your Quarto document
