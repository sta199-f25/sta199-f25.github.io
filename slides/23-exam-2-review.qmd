---
title: "Exam 2 review"
subtitle: "Lecture 23"
date: "2025-11-18"
format: 
  revealjs: 
    output-file: 23-exam-2-review-slides.html
    footer: "[ðŸ”— sta199-f25.github.io](https://sta199-f25.github.io/)"
    theme: slides.scss
    transition: fade
    slide-number: true
    logo: images/logo.png
    pdf-separate-fragments: true
    toc: false
  html: 
    code-link: true
filters: 
  - ../remove-fmt-skip.lua
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
ggplot2::theme_set(ggplot2::theme_bw(base_size = 24))
todays_ae <- "ae-14-chicago-taxi-classification"
```

# Warm-up

## Announcements {.smaller}

- Exam - In class:
    - Cheat sheet: 8.5x11, both sides, hand written or typed, any content you want, must be prepared by you
    - Bring a pencil and eraser (youâ€™re allowed to use a pen, but you might not want to)

- Exam - Take home:
  - Open book, notes, internet
  - No office hours
  - Questions on Ed (private by default)
  - Due Saturday, November 22 at noon

- Reminder: Academic dishonesty / Duke Community Standard

- Next Tuesday: Can watch class live on Panopto link

## From last class: `{r} todays_ae` {.smaller}

::: appex
Finish up the application exercise by finding the area under the ROC curve.
:::

## Recap {.xsmall}

::: incremental
- Split data into training and testing sets (generally 75/25)

- Fit models on training data and reduce to a few candidate models

- Make predictions on testing data

- Evaluate predictions on testing data using appropriate predictive performance metrics
  - Linear models: Adjusted R-squared, AIC, etc.
  - Logistic models: False negative and positive rates, AUC (area under the curve), etc.

- Don't forget to also consider explainability and domain knowledge when selecting a final model

- In a future machine learning course: Cross-validation (partitioning training data into training and validation sets and repeating this many times to evaluate model predictive performance before using the testing data), feature engineering,  hyperparameter tuning, more complex models (random forests, gradient boosting machines, neural networks, etc.)
:::

# Modeling review

## Hotel cancellations

```{r}
#| message: false
library(tidyverse)
library(tidymodels)
```

```{r}
#| eval: false
hotels <- read_csv("data/hotels.csv")
```

```{r}
#| include: false
hotels <- read_csv(here::here("slides", "data/hotels.csv"))
```

## Data prep {.smaller}

- Relevel `is_canceled`
- Remove bookings with average daily rate greater than $1,000
- Remove bookings with number of adults greater than or equal to 5
- Split the data into a training set (75%) and a testing set (25%)

```{r}
#| code-line-numbers: "|2-5|6|1|8-11"
hotels <- hotels |>
  mutate(
    is_canceled = if_else(is_canceled == 1, "canceled", "not canceled"),
    is_canceled = fct_relevel(is_canceled, "not canceled", "canceled")
  ) |>
  filter(adr <= 1000, adults < 5)

set.seed(1117)
hotels_split <- initial_split(hotels)
hotels_train <- training(hotels_split)
hotels_test <- testing(hotels_split)
```

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

What type of model would you use to answer the question:

> Are reservations earlier in the month or later in the month more likely to be cancelled?

::: wooclap-choices
- Linear regression with a numerical predictor
- Linear regression with a categorical predictor
- Linear regression with a log-transformed outcome and a numerical predictor
- Linear regression with a log-transformed outcome and a categorical predictor
- Logistic regression with a numerical predictor [âœ…]{.fragment}
- Logistic regression with a categorical predictor
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Linear regression

Numerical outcome:

$$
y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k + \varepsilon
$$

<br>

$$
\widehat{y} = b_0 + b_1 x_1 + b_2 x_2 + \cdots + b_k x_k
$$

## Linear regression with log-transformed outcome

Numerical outcome, log-transformed for a better linear fit:

$$
log(y) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k + \varepsilon
$$

<br>

$$
log(\widehat{y}) = b_0 + b_1 x_1 + b_2 x_2 + \cdots + b_k x_k
$$

## Logistic regression

Binary outcome, where $p = P(Y=1)$, the probability of success:

$$
\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \cdots + \beta_k x_k + \varepsilon
$$

<br>

$$
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) = b_0 + b_1 x_1 + b_2 x_2 + \cdots + b_k x_k
$$

## Cancellation ~ arrival date {.smaller}

```{r}
is_canceled_fit_1 <- logistic_reg() |>
  fit(is_canceled ~ arrival_date_day_of_month, data = hotels_train)

tidy(is_canceled_fit_1)
```

## Slope in logistic regression {.smaller}

```{r}
tidy(is_canceled_fit_1) |>
  select(term, estimate) |>
  mutate(exp_estimate = exp(estimate))
```

. . .

<br>

For each day the booking is later in the month, the odds of reservations being canceled is predicted to be lower by a factor of 0.998, on average.

## Intercept in logistic regression {.smaller}

```{r}
tidy(is_canceled_fit_1) |>
  select(term, estimate) |>
  mutate(exp_estimate = exp(estimate))
```

. . .

<br>

On the 0th day of the month, the odds of reservations being canceled is predicted to be 0.601, on average.
The intercept is not meaningful in this context since there is no 0th day of the month.

## Prediction in logistic regression {.smaller}

::: task
Predict the probability of cancellation for a booking made on the 18th day of the month.
:::

. . .

```{r}
new_booking <- tibble(arrival_date_day_of_month = 18)
augment(is_canceled_fit_1, new_data = new_booking)
```

## `augment()` vs. `predict()` {.smaller}

- `augment()` returns the data frame passed to `new_data` _augment_ed by
  - the predicted probability of success,
  - the predicted probability of success, and
  - the predicted class (based on a 0.5 cutoff by default)

```{r}
augment(is_canceled_fit_1, new_data = new_booking)
```

. . .

- `predict()` the predicted class (based on a 0.5 cutoff by default)

```{r}
predict(is_canceled_fit_1, new_data = new_booking)
```

## Cancellation ~ arrival date + hotel type {.smaller}

::: task
Fit another model to predict whether a reservation was cancelled from `arrival_date_day_of_month` and `hotel` type (Resort or City Hotel), allowing the relationship between `arrival_date_day_of_month` and `is_canceled` to **not** vary based on `hotel` type.
:::

. . .

```{r}
is_canceled_fit_2 <- logistic_reg() |>
  fit(is_canceled ~ arrival_date_day_of_month + hotel, data = hotels_train)

tidy(is_canceled_fit_2)
```

## Slope in logistic regression {.smaller}

```{r}
tidy(is_canceled_fit_2) |>
  select(term, estimate) |>
  mutate(exp_estimate = exp(estimate))
```

. . .

<br>

Holding hotel type constant, for each day the booking is later in the month, the odds of reservations being canceled is predicted to be lower by a factor of 0.998, on average.

## Slope in logistic regression {.smaller}

```{r}
tidy(is_canceled_fit_2) |>
  select(term, estimate) |>
  mutate(exp_estimate = exp(estimate))
```

. . .

<br>

Holding arrival day of month constant, the odds of Resort Hotel reservations being canceled is predicted to be lower by a factor of 0.541 compared to City Hotel reservations, on average.

## Intercept in logistic regression {.smaller}

```{r}
tidy(is_canceled_fit_2) |>
  select(term, estimate) |>
  mutate(exp_estimate = exp(estimate))
```

. . .

<br>

On the 0th day of the month, the odds of City Hotel reservations being canceled is predicted to be 0.729, on average.
The intercept is not meaningful in this context since there is no 0th day of the month.

## Cancellation ~ arrival date * hotel type {.smaller}

::: task
Fit another model to predict whether a reservation was cancelled from `arrival_date_day_of_month` and `hotel` type (Resort or City Hotel), allowing the relationship between `arrival_date_day_of_month` and `is_canceled` to vary based on `hotel` type.
:::

. . .

```{r}
is_canceled_fit_3 <- logistic_reg() |>
  fit(is_canceled ~ arrival_date_day_of_month * hotel, data = hotels_train)

tidy(is_canceled_fit_3)
```

## Logistic regression w/ interaction effect {.smaller}

```{r}
tidy(is_canceled_fit_3) |>
  select(term, estimate)
```

<br>

. . .

$$
\begin{aligned}
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) &= -0.321 \\
&- 0.00117 \times \texttt{arrival_date_day_of_month} \\
&- 0.594 \times \texttt{hotelResort Hotel} \\
&- 0.00125 \times \texttt{arrival_date_day_of_month:hotelResort Hotel} \\
\end{aligned}
$$

## Logistic regression w/ interaction effect {.smaller .scrollable}

$$
\begin{aligned}
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) &= -0.321 \\
&- 0.00117 \times \texttt{arrival_date_day_of_month} \\
&- 0.594 \times \texttt{hotelResort Hotel} \\
&- 0.00125 \times \texttt{arrival_date_day_of_month:hotelResort Hotel} \\
\end{aligned}
$$

<br>

. . .

**City Hotel:**

$$
\begin{aligned}
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) &= -0.321 \\
&- 0.00117 \times \texttt{arrival_date_day_of_month} \\
&- 0.594 \times 0 \\
&- 0.00125 \times \texttt{arrival_date_day_of_month} \times 0 \\
\\
&= -0.321 - 0.00117 \times \texttt{arrival_date_day_of_month} \\
\end{aligned}
$$

## Logistic regression w/ interaction effect {.smaller .scrollable}

$$
\begin{aligned}
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) &= -0.321 \\
&- 0.00117 \times \texttt{arrival_date_day_of_month} \\
&- 0.594 \times \texttt{hotelResort Hotel} \\
&- 0.00125 \times \texttt{arrival_date_day_of_month:hotelResort Hotel} \\
\end{aligned}
$$

<br>

. . .

**Resort Hotel:**

$$
\begin{aligned}
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) &= -0.321 \\
&- 0.00117 \times \texttt{arrival_date_day_of_month} \\
&- 0.594 \times 1 \\
&- 0.00125 \times \texttt{arrival_date_day_of_month} \times 1 \\
\\
&= -(0.321+0.594) - (0.00117+0.00125) \times \texttt{arrival_date_day_of_month} \\
\\
&= -0.915 - 0.00242 \times \texttt{arrival_date_day_of_month} \\
\end{aligned}
$$

## Logistic regression w/ interaction effect {.smaller}

**City Hotel:**

$$
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) = -0.321 - 0.00117 \times \texttt{arrival_date_day_of_month}
$$

- `exp(-0.00117)` = `{r} round(exp(-0.00117), 3)`: In City Hotels, for each day the booking is later in the month, the odds of reservations being canceled is predicted to be lower by a factor of 0.999, on average.

- `exp(âˆ’0.321)` = `{r} round(exp(-0.321), 3)`: In City Hotels, on the 0th day of the month, the odds of reservations being canceled is predicted to be 0.725, on average.
The intercept is not meaningful in this context since there is no 0th day of the month.

## Logistic regression w/ interaction effect {.smaller}

**Resort Hotel:**

$$
\log\left(\frac{\widehat{p}}{1-\widehat{p}}\right) = -0.915 - 0.00242 \times \texttt{arrival_date_day_of_month}
$$

- `exp(-0.00117)` = `{r} round(exp(-0.00242), 3)`: In Resort Hotels, for each day the booking is later in the month, the odds of reservations being canceled is predicted to be lower by a factor of 0.998, on average.

- `exp(âˆ’0.321)` = `{r} round(exp(-0.915), 3)`: In Resort Hotels, on the 0th day of the month, the odds of reservations being canceled is predicted to be 0.401, on average.
The intercept is not meaningful in this context since there is no 0th day of the month.

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

Suppose we want to select a final model to predict whether a reservation was cancelled. Which metric would be most appropriate to evaluate the predictive performance of our logistic regression models?

::: wooclap-choices
- True positive rate
- Area under the ROC curve [âœ…]{.fragment}
- Adjusted R-squared
- Root mean squared error
- R-squared
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Area under the ROC curve (AUC) {.xsmall}

```{r}
is_canceled_aug_1 <- augment(is_canceled_fit_1, new_data = hotels_test)
is_canceled_aug_2 <- augment(is_canceled_fit_2, new_data = hotels_test)
is_canceled_aug_3 <- augment(is_canceled_fit_3, new_data = hotels_test)
```

::: {.columns}

::: {.column width="33%" .fragment}

Single predictor:

```{r}
roc_auc(
  is_canceled_aug_1,
  truth = is_canceled,
  .pred_canceled,
  event_level = "second"
)
```

:::

::: {.column width="33%" .fragment}

Main effects:

```{r}
roc_auc(
  is_canceled_aug_2,
  truth = is_canceled,
  .pred_canceled,
  event_level = "second"
)
```

:::

::: {.column width="33%" .fragment}

Interaction effects:

```{r}
roc_auc(
  is_canceled_aug_3,
  truth = is_canceled,
  .pred_canceled,
  event_level = "second"
)
```

:::

::: 

::: {.task .fragment}
Which model would you select as your final model based on AUC?
:::

## Linear regression

The dataset also contains information about the average daily rate (`adr`) for each reservation.
The following model predicts `adr` from `adults` and `hotel` type.

```{r}
#| eval: true
#| echo: false
adr_fit_1 <- linear_reg() |>
  fit(adr ~ adults + hotel, data = hotels_train)

adr_aug_1 <- augment(adr_fit_1, hotels_train)

tidy(adr_fit_1)
```

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

Which of the following is the best interpretation of the slope coefficient for `adults`?

```{r}
#| echo: false
tidy(adr_fit_1)
```

For each additional adult in the booking, the average daily rate is predicted to be higher by \$29.50

::: wooclap-choices
- on average, holding hotel type constant. [âœ…]{.fragment}
- for Resort Hotels compared to City Hotels, on average.
- for City Hotels compared to Resort Hotels, on average.
- on average, not holding any other variables constant.
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: {.wooclap .medium}

Which of the following is the correct interpretation of the slope coefficient for `hotel`?

```{r}
#| echo: false
tidy(adr_fit_1)
```

::: wooclap-choices
- For each additional Resort Hotel booking, the predicted average daily rate is \$10.70 lower, holding number of adults constant.
- For each additional adult in the booking, the average daily rate is predicted to be lower by \$10.70 for resort hotels compared to City Hotels, on average.
- Resort Hotels bookings are predicted to have an average daily rate that is \$10.70 lower than City Hotels, on average, holding number of adults constant. [âœ…]{.fragment}
- Resort Hotels bookings are predicted to have an average daily rate that is \$10.70 higher than City Hotels, on average, holding number of adults constant.
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

Which of the following is the correct interpretation of the intercept?

```{r}
#| echo: false
tidy(adr_fit_1)
```

::: wooclap-choices
- The predicted average daily rate for a bookings with 0 adults at a Resort Hotel is \$50.50, on average.
- The predicted average daily rate for a bookings with 0 adults at a City Hotel is \$50.50, on average. [âœ…]{.fragment}
- For each additional adult and Resort Hotel in the booking, the average daily rate is predicted to be \$50.50 higher, on average.
- For each additional adult and City Hotel in the booking, the average daily rate is predicted to be \$50.50 higher, on average.
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::

## Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

Which of the following (Plot A or Plot B) is the correct visual representation of this model?

```{r}
#| echo: false
#| eval: true
#| message: false
#| layout-ncol: 2
#| fig-width: 5
#| fig-asp: 0.618
ggplot(hotels_train, aes(x = adults, y = adr, color = hotel)) +
  geom_point() +
  geom_smooth(method = "lm", linewidth = 1, se = FALSE) +
  ggthemes::scale_color_colorblind() +
  labs(
    title = "Plot A",
    x = "Number of adults",
    y = "Average daily rate",
    color = "Hotel"
  ) +
  theme_minimal() +
  theme(legend.position = "inside", legend.position.inside = c(0.15, 0.80))

ggplot(adr_aug_1, aes(x = adults, color = hotel)) +
  geom_point(aes(y = adr)) +
  geom_line(aes(y = .pred), linewidth = 1) +
  ggthemes::scale_color_colorblind() +
  labs(
    title = "Plot B",
    x = "Number of adults",
    y = "Average daily rate",
    color = "Hotel"
  ) +
  theme_minimal() +
  theme(legend.position = "inside", legend.position.inside = c(0.15, 0.80))
```

::: wooclap-choices
- Plot A
- Plot B [âœ…]{.fragment}
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::
