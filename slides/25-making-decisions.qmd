---
title: "Making decisions"
subtitle: "Lecture 25"
date: "2025-12-02"
format: 
  revealjs: 
    output-file: 25-quantifying-uncertainty-slides.html
    footer: "[ðŸ”— sta199-f25.github.io](https://sta199-f25.github.io/)"
    theme: slides.scss
    transition: fade
    slide-number: true
    logo: images/logo.png
    pdf-separate-fragments: true
    toc: false
  html: 
    code-link: true
filters: 
  - ../remove-fmt-skip.lua
editor_options: 
  chunk_output_type: console
---

```{r}
#| label: setup
#| include: false
ggplot2::theme_set(ggplot2::theme_bw(base_size = 24))
todays_ae <- "XXX"
```

# Warm-up

## While you wait: Participate ðŸ“±ðŸ’» {.xsmall}

::: columns

::: {.column width="70%"}

::: wooclap

...

::: wooclap-choices
- ...
:::

:::

:::

::: {.column width="30%"}
{{< include _wooclap-column.qmd >}}
:::

:::


## Announcements {.xsmall}

- HW:
  - HW 5 accepted until Wed, Dec 3 at 11:59 pm without penalty
  - HW 6 due at 11:59 pm on Fri, Dec 6, accepted until Sun, Dec 7 at 11:59 pm without penalty

- Final exam: 
  - Classroom: Half of you will take it in this room (Bio Sci 111) the other half in (Physics 128), watch your email for your classroom assignment
  - Review: During reading period, date/time TBA

# From last time

## Goal + setup

Find range of plausible values for the slope using bootstrap confidence intervals.

```{r}
#| message: false
library(tidyverse)
library(tidymodels)
library(openintro)
```

## Computing the CI for the slope I

Calculate the observed slope:

```{r}
#| echo: true
observed_fit <- duke_forest |>
  specify(price ~ area) |>
  fit()

observed_fit
```

## Computing the CI for the slope II {.smaller}

Take `1000` bootstrap samples and fit models to each one:

```{r}
#| code-line-numbers: "1,5,6"
set.seed(1120)

boot_fits <- duke_forest |>
  specify(price ~ area) |>
  generate(reps = 1000, type = "bootstrap") |>
  fit()

boot_fits
```

## Computing the CI for the slope III

**Percentile method:** Compute the 95% CI as the middle 95% of the bootstrap distribution:

```{r}
#| code-line-numbers: "5"
get_confidence_interval(
  boot_fits,
  point_estimate = observed_fit,
  level = 0.95,
  type = "percentile" # default method
)
```

## Precision vs. accuracy {.smaller}

::: task
If we want to be very certain that we capture the population parameter, should we use a wider or a narrower interval?
What drawbacks are associated with using a wider interval?
:::

. . .

![](images/24/garfield.png)

## Precision vs. accuracy {.smaller}

::: task
How can we get best of both worlds -- high precision and high accuracy?
:::

## Changing confidence level {.smaller}

::: task
How would you modify the following code to calculate a 90% confidence interval?
How would you modify it for a 99% confidence interval?
:::

```{r}
#| code-line-numbers: "|4"
get_confidence_interval(
  boot_fits,
  point_estimate = observed_fit,
  level = 0.95,
  type = "percentile"
)
```

## Changing confidence level {.smaller}

::: {.columns}

::: {.column}

**Confidence level: 90%**

```{r}
#| code-line-numbers: "4"
get_confidence_interval(
  boot_fits,
  point_estimate = observed_fit,
  level = 0.90,
  type = "percentile"
)
```

:::

::: {.column}

**Confidence level: 99%**

```{r}
#| code-line-numbers: "4"
get_confidence_interval(
  boot_fits,
  point_estimate = observed_fit,
  level = 0.99,
  type = "percentile"
)
```

:::

:::

## Recap {.xsmall}

::: incremental

-   **Population:** Complete set of observations of whatever we are studying, e.g., people, tweets, photographs, etc. -- population size = $N$

-   **Sample:** Subset of the population, ideally random and representative -- sample size = $n$

-   Sample statistic $\ne$ population parameter, but if the sample is good, it can be a good estimate

-   **Statistical inference:** Discipline that concerns itself with the development of procedures, methods, and theorems that allow us to extract meaning and information from data that has been generated by stochastic (random) process

-   We report the estimate with a confidence interval, and the width of this interval depends on the variability of sample statistics from different samples from the population

-   Since we can't continue sampling from the population, we bootstrap from the one sample we have to estimate sampling variability

:::

## Why do we construct confidence intervals?

To estimate plausible values of a parameter of interest, e.g., a slope ($\beta_1$), a mean ($\mu$), a proportion ($p$).

## What is bootstrapping?

-   Bootstrapping is a statistical procedure that resamples(with replacement) a single data set to create many simulated samples.

-   We then use these simulated samples to quantify the uncertainty around the sample statistic we're interested in, e.g., a slope ($b_1$), a mean ($\bar{x}$), a proportion ($\hat{p}$).

## What does each observation on the plot represent? {.smaller}

::: {.columns}

::: {.column}
-   Resample, with replacement, from the original data
-   Do this `reps = 1000` times
-   Calculate the summary statistic of interest in each of these samples
:::

::: {.column}
```{r}
#| echo: false
#| fig-asp: 1
visualize(boot_fits)
```
:::

:::


## Bootstrapping for categorical data

-   `specify(response = x, success = "success level")`

-   `calculate(stat = "prop")`

## Bootstrapping for other `stat`s

-   `calculate()` documentation: [infer.tidymodels.org/reference/calculate.html](https://infer.tidymodels.org/reference/calculate.html)

-   **infer** pipelines: [infer.tidymodels.org/articles/observed_stat_examples.html](https://infer.tidymodels.org/articles/observed_stat_examples.html)

# Hypothesis testing

## Hypothesis testing

A hypothesis test is a statistical technique used to evaluate *competing claims* using data

::: incremental
-   **Null hypothesis,** $H_0$: An assumption about the population.
    "There is nothing going on."

-   **Alternative hypothesis,** $H_A$: A research question about the population.
    "There is something going on".
:::

. . .

Note: Hypotheses are always at the population level!

## Setting hypotheses

-   **Null hypothesis,** $H_0$: "There is nothing going on." The slope of the model for predicting the prices of houses in Duke Forest from their areas is 0, $\beta_1 = 0$.

-   **Alternative hypothesis,** $H_A$: "There is something going on".
    The slope of the model for predicting the prices of houses in Duke Forest from their areas is different than, $\beta_1 \ne 0$.

## Hypothesis testing "mindset"

-   Assume you live in a world where null hypothesis is true: $\beta_1 = 0$.

-   Ask yourself how likely you are to observe the sample statistic, or something even more extreme, in this world: 

$$P \big( b_1 \leq 159~or~b_1 \geq 159 ~|~ \beta_1 = 0 \big)$$

## Hypothesis testing as a court trial {.smaller}

-   **Null hypothesis**, $H_0$: Defendant is innocent

-   **Alternative hypothesis**, $H_A$: Defendant is guilty

. . .

-   **Present the evidence:** Collect data

. . .

-   **Judge the evidence:** "Could these data plausibly have happened by chance if the null hypothesis were true?"
    -   Yes: Fail to reject $H_0$
    -   No: Reject $H_0$

## Hypothesis testing framework {.smaller}

::: incremental
-   Start with a null hypothesis, $H_0$, that represents the status quo

-   Set an alternative hypothesis, $H_A$, that represents the research question, i.e. what weâ€™re testing for

-   Conduct a hypothesis test under the assumption that the null hypothesis is true and calculate a **p-value** (probability of observed or more extreme outcome given that the null hypothesis is true)

    -   if the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis
    -   if they do, then reject the null hypothesis in favor of the alternative
:::

## Calculate observed slope

...
which we have already done:

```{r}
observed_fit <- duke_forest |>
  specify(price ~ area) |>
  fit()

observed_fit
```

## Simulate null distribution

```{r}
#| code-line-numbers: "|1|2|3|4|5|6"
set.seed(20251202)
null_dist <- duke_forest |>
  specify(price ~ area) |>
  hypothesize(null = "independence") |>
  generate(reps = 1000, type = "permute") |>
  fit()
```

## View null distribution {.smaller}

```{r}
null_dist
```

## Visualize null distribution {.smaller}

```{r}
#| fig-asp: 1
visualize(null_dist)
```

## Visualize null distribution + p-value

```{r}
#| fig-asp: 1
#| output-location: column
visualize(null_dist) +
  shade_p_value(
    obs_stat = observed_fit, 
    direction = "two-sided"
  )
```

## Get p-value {.smaller}

```{r}
null_dist |>
  get_p_value(obs_stat = observed_fit, direction = "two-sided")
```

## Make a decision

::: task
Based on the p-value calculated, what is the conclusion of the hypothesis test?
:::
